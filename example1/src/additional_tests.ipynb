{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce493ed0-81e4-4a3f-92c7-6d4820280c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from scipy import io\n",
    "\n",
    "from models import DeepONet, BelNet, StochasticFeatures\n",
    "from utils import get_data, train_model, validate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193cc98-083e-4857-a695-d1e1afaa3836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing model 0\n",
      "Validation Loss: 0.00060, mean Relative L2 Loss: 0.02260, R-squared: 0.99765\n",
      "(1200, 32)\n",
      "Validation Loss: 0.00058, mean Relative L2 Loss: 0.02317, R-squared: 0.99771\n"
     ]
    }
   ],
   "source": [
    "def test_loaded_model(path, model):\n",
    "    criterion = nn.MSELoss()  \n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    '''\n",
    "        test on data same as training time\n",
    "    '''\n",
    "    np.random.seed(42) # fixed seed\n",
    "    train_data, test_data = get_data(1000,200)\n",
    "    train_data= [torch.from_numpy(d).float().to(device).reshape((1000,128,1)) for d in train_data]\n",
    "    test_data = [torch.from_numpy(d).float().to(device).reshape((200,128,1)) for d in test_data]\n",
    "    (x_train, a_train, y_train, u_train) = train_data\n",
    "    (x_test, a_test, y_test, u_test)     = test_data\n",
    "    # print(\"train shape:\", x_train.shape, a_train.shape, y_train.shape, u_train.shape)\n",
    "    # print(\"test shape:\", x_test.shape, a_test.shape, y_test.shape, u_test.shape)\n",
    "        \n",
    "    validate_model(model, test_data, criterion, device=device)\n",
    "    \n",
    "    '''\n",
    "        test on interpolated data\n",
    "    '''\n",
    "    def get_data_subsample_input(ntrain, ntest):\n",
    "        N = ntrain + ntest\n",
    "        data = io.loadmat(\"../Burgers/burgers_data_R10.mat\")\n",
    "    \n",
    "        def get_fixed_indices_input(N):\n",
    "            indices_1 = np.arange(0, 2**13, 2**6)\n",
    "            index_array = np.zeros((N, 2**7), dtype=int) \n",
    "            for n in range(N):\n",
    "                index_array[n] = indices_1\n",
    "            index_array = index_array[:,2::4]\n",
    "            print(index_array.shape)\n",
    "            return index_array\n",
    "    \n",
    "        def get_fixed_indices_output(N):\n",
    "            indices_1 = np.arange(0, 2**13, 2**6)\n",
    "            index_array = np.zeros((N, 2**7), dtype=int) \n",
    "            for n in range(N):\n",
    "                index_array[n] = indices_1\n",
    "            return index_array\n",
    "    \n",
    "        input_func_data  = data[\"a\"][:N, :].astype(np.float32)\n",
    "        output_func_data = data[\"u\"][:N, :].astype(np.float32)\n",
    "\n",
    "        from scipy.interpolate import interp1d\n",
    "        input_index_array = get_fixed_indices_input(N)\n",
    "        raw_a_data = input_func_data[np.arange(N)[:, None], input_index_array]\n",
    "        a_data = np.zeros((N, 128))\n",
    "        for i in range(N):\n",
    "            f = interp1d(input_index_array[i,:], raw_a_data[i,:], kind='linear', fill_value=\"extrapolate\")\n",
    "            a_data[i,:] = f(np.arange(0, 2**13, 2**6))\n",
    "                \n",
    "        output_index_array = get_fixed_indices_output(N)\n",
    "        y_data = output_index_array * (1.0 / 2**13)\n",
    "        u_data = output_func_data[np.arange(N)[:, None], output_index_array]\n",
    "    \n",
    "        train_data = (np.zeros((1000,1)), a_data[:ntrain], y_data[:ntrain], u_data[:ntrain]) \n",
    "        test_data  = (np.zeros((200,1)), a_data[ntrain:], y_data[ntrain:], u_data[ntrain:])\n",
    "        return train_data, test_data\n",
    "    \n",
    "    np.random.seed(42) # fixed seed\n",
    "    train_data, test_data = get_data_subsample_input(1000,200)\n",
    "    train_data= [torch.from_numpy(d).float().to(device).unsqueeze(2) for d in train_data]\n",
    "    test_data = [torch.from_numpy(d).float().to(device).unsqueeze(2) for d in test_data]\n",
    "    (x_train, a_train, y_train, u_train) = train_data\n",
    "    (x_test, a_test, y_test, u_test)     = test_data\n",
    "    # print(\"train shape:\", x_train.shape, a_train.shape, y_train.shape, u_train.shape)\n",
    "    # print(\"test shape:\", x_test.shape, a_test.shape, y_test.shape, u_test.shape)\n",
    "    validate_model(model, test_data, criterion, device=device)\n",
    "\n",
    "paths = [\n",
    "    '../saved_models/model_save_0.pth',\n",
    "]\n",
    "models = [\n",
    "    DeepONet(),\n",
    "]\n",
    "\n",
    "for model_idx, (path, model) in enumerate(zip(paths, models)):\n",
    "    print(f\"testing model {model_idx}\")\n",
    "    test_loaded_model(path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab82865-ec5f-4397-9535-5121de304ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.00027, mean Relative L2 Loss: 0.01553, R-squared: 0.99894\n",
      "(1200, 32)\n",
      "Validation Loss: 0.00029, mean Relative L2 Loss: 0.01706, R-squared: 0.99888\n",
      "testing model 2\n",
      "Validation Loss: 0.00029, mean Relative L2 Loss: 0.01582, R-squared: 0.99888\n",
      "(1200, 32)\n",
      "Validation Loss: 0.00031, mean Relative L2 Loss: 0.01795, R-squared: 0.99877\n",
      "testing model 3\n",
      "Validation Loss: 0.00024, mean Relative L2 Loss: 0.01466, R-squared: 0.99904\n",
      "(1200, 32)\n",
      "Validation Loss: 0.00026, mean Relative L2 Loss: 0.01702, R-squared: 0.99896\n",
      "testing model 4\n",
      "Validation Loss: 0.00029, mean Relative L2 Loss: 0.01624, R-squared: 0.99887\n",
      "(1200, 32)\n",
      "Validation Loss: 0.00029, mean Relative L2 Loss: 0.01751, R-squared: 0.99885\n"
     ]
    }
   ],
   "source": [
    "def test_loaded_model(path, model):\n",
    "    criterion = nn.MSELoss()  \n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    '''\n",
    "        test on data same as training time\n",
    "    '''\n",
    "    np.random.seed(42) # fixed seed\n",
    "    train_data, test_data = get_data(1000,200)\n",
    "    train_data= [torch.from_numpy(d).float().to(device).reshape((1000,128,1)) for d in train_data]\n",
    "    test_data = [torch.from_numpy(d).float().to(device).reshape((200,128,1)) for d in test_data]\n",
    "    (x_train, a_train, y_train, u_train) = train_data\n",
    "    (x_test, a_test, y_test, u_test)     = test_data\n",
    "    # print(\"train shape:\", x_train.shape, a_train.shape, y_train.shape, u_train.shape)\n",
    "    # print(\"test shape:\", x_test.shape, a_test.shape, y_test.shape, u_test.shape)\n",
    "        \n",
    "    validate_model(model, test_data, criterion, device=device)\n",
    "\n",
    "    '''\n",
    "        test on one-fourth of input data\n",
    "    '''\n",
    "    def get_data_subsample_input(ntrain, ntest):\n",
    "        N = ntrain + ntest\n",
    "        data = io.loadmat(\"../Burgers/burgers_data_R10.mat\")\n",
    "    \n",
    "        def get_fixed_indices_input(N, num_samples):\n",
    "            indices_1 = np.arange(0, 2**13, 2**6)\n",
    "            index_array = np.zeros((N, 2**7), dtype=int) \n",
    "            for n in range(N):\n",
    "                index_array[n] = indices_1\n",
    "            index_array = index_array[:,2::4]\n",
    "            print(index_array.shape)\n",
    "            return index_array\n",
    "    \n",
    "        def get_fixed_indices_output(N):\n",
    "            indices_1 = np.arange(0, 2**13, 2**6)\n",
    "            index_array = np.zeros((N, 2**7), dtype=int) \n",
    "            for n in range(N):\n",
    "                index_array[n] = indices_1\n",
    "            return index_array\n",
    "    \n",
    "        input_func_data  = data[\"a\"][:N, :].astype(np.float32)\n",
    "        output_func_data = data[\"u\"][:N, :].astype(np.float32)\n",
    "\n",
    "        input_index_array = get_fixed_indices_input(N, num_samples = 32)\n",
    "        x_data = input_index_array * (1.0 / 2**13)\n",
    "        a_data = input_func_data[np.arange(N)[:, None], input_index_array]\n",
    "\n",
    "        def interpolate_inputs(arr, multi):\n",
    "            N,m = arr.shape\n",
    "            new_arr = np.concatenate([arr, arr[:,-1:]], axis=1)\n",
    "            a = new_arr[:, :-1]  \n",
    "            b = new_arr[:, 1:]   \n",
    "            result = np.empty((arr.shape[0], multi*m), dtype=arr.dtype)\n",
    "            result[:, 0::multi] = arr\n",
    "            for i in range(1,multi):\n",
    "                result[:, i::multi] = (1-i/multi) * a + (i/multi) * b\n",
    "        \n",
    "            return result\n",
    "        \n",
    "        output_index_array = get_fixed_indices_output(N)\n",
    "        y_data = output_index_array * (1.0 / 2**13)\n",
    "        u_data = output_func_data[np.arange(N)[:, None], output_index_array]\n",
    "    \n",
    "        train_data = (x_data[:ntrain], a_data[:ntrain], y_data[:ntrain], u_data[:ntrain]) \n",
    "        test_data  = (x_data[ntrain:], a_data[ntrain:], y_data[ntrain:], u_data[ntrain:])\n",
    "        return train_data, test_data\n",
    "    \n",
    "    np.random.seed(42) # fixed seed\n",
    "    train_data, test_data = get_data_subsample_input(1000,200)\n",
    "    train_data= [torch.from_numpy(d).float().to(device).unsqueeze(2) for d in train_data]\n",
    "    test_data = [torch.from_numpy(d).float().to(device).unsqueeze(2) for d in test_data]\n",
    "    (x_train, a_train, y_train, u_train) = train_data\n",
    "    (x_test, a_test, y_test, u_test)     = test_data\n",
    "    # print(\"train shape:\", x_train.shape, a_train.shape, y_train.shape, u_train.shape)\n",
    "    # print(\"test shape:\", x_test.shape, a_test.shape, y_test.shape, u_test.shape)\n",
    "    validate_model(model, test_data, criterion, device=device)\n",
    "\n",
    "paths = [\n",
    "    '../saved_models/model_save_1.pth',\n",
    "    '../saved_models/model_save_2.pth',\n",
    "    '../saved_models/model_save_3.pth',\n",
    "    '../saved_models/model_save_4.pth',\n",
    "]\n",
    "models = [\n",
    "    BelNet(num_learned_basis = 50, num_fixed_basis = 0),\n",
    "    BelNet(),\n",
    "    BelNet(),\n",
    "    BelNet(),\n",
    "]\n",
    "\n",
    "for model_idx, (path, model) in enumerate(zip(paths, models)):\n",
    "    print(f\"testing model {model_idx+1}\")\n",
    "    test_loaded_model(path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9358b-c08b-45d0-bb7d-6519f1ef12f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
