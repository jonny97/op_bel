{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74520b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import io\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801cb463",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "140e9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ntrain, ntest):\n",
    "    np.random.seed(42) # fixed seed\n",
    "    N = ntrain + ntest\n",
    "    data = io.loadmat(\"../data/dataGRFshorttspan.mat\")\n",
    "\n",
    "    def get_input_indices(N):\n",
    "        indices_1 = np.arange(0, 2**13, 2**6)\n",
    "        index_array = np.zeros((N, 2**7), dtype=int) \n",
    "        for n in range(N):\n",
    "            index_array[n] = indices_1\n",
    "        return index_array\n",
    "\n",
    "\n",
    "    input_index_array = get_input_indices(N)\n",
    "    input_func_data  = data[\"output\"][:N, :].astype(np.float32)\n",
    "    x_data = input_index_array * (1.0 / 2**13)\n",
    "    a_data = input_func_data[np.arange(N)[:, None], input_index_array]\n",
    "\n",
    "    from scipy.interpolate import interp1d\n",
    "    data_grid = np.linspace(0, 1, 8193)\n",
    "    y_data = np.random.uniform(0, 1, (N, 1000, 2))\n",
    "    charateristic = (y_data[:,:,0] - y_data[:,:,1]) % 1\n",
    "\n",
    "    u_data = np.zeros((N, 1000, 1))\n",
    "    for idx in range(N):\n",
    "        f_data = data[\"output\"][idx,:]\n",
    "        f_data = np.append(f_data, f_data[0]) \n",
    "        f = interp1d(data_grid, f_data, kind='linear', fill_value='periodic')\n",
    "        u_data[idx,:,0] = f(charateristic[idx,:])\n",
    "\n",
    "    train_data = (x_data[:ntrain,:,None], a_data[:ntrain,:,None], y_data[:ntrain], u_data[:ntrain]) \n",
    "    test_data  = (x_data[ntrain:,:,None], a_data[ntrain:,:,None], y_data[ntrain:], u_data[ntrain:])\n",
    "    return train_data, test_data\n",
    "    \n",
    "def inverse_time_decay(epoch, initial_lr, decay_factor, decay_epochs):\n",
    "    \"\"\"Inverse time decay function.\"\"\"\n",
    "    return initial_lr / (1 + decay_factor * (epoch / decay_epochs))\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_data, test_data, criterion, optimizer, num_epochs, device):\n",
    "    x_train, a_train, y_train, u_train = train_data\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = inverse_time_decay(epoch, initial_lr=0.001, decay_factor=0.5, decay_epochs=100000)\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        outputs = model(x_train, a_train, y_train)\n",
    "        loss = criterion(outputs, u_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss = loss.item()\n",
    "        train_losses.append(epoch_loss)\n",
    "        if epoch % 5000 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "            validate_model(model, test_data, criterion, device=device)\n",
    "    return train_losses\n",
    "\n",
    "def validate_model(model, test_data, criterion, device):\n",
    "    x_test, a_test, y_test, u_test = test_data\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    rel_l2_loss = 0.0\n",
    "    with torch.no_grad():  # Disable gradient calculation during validation\n",
    "        actual_batch_size = u_test.shape[0]\n",
    "        outputs = model(x_test, a_test, y_test)\n",
    "        loss = criterion(outputs, u_test)\n",
    "        val_loss += loss.item()\n",
    "        diff_norms = torch.norm(outputs.reshape(actual_batch_size,-1) - u_test.reshape(actual_batch_size,-1), dim=1)\n",
    "        y_norms = torch.norm(u_test.reshape(actual_batch_size,-1), dim=1)\n",
    "        rel_l2_loss += torch.mean(diff_norms/y_norms)   \n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss:.5f}, mean Relative L2 Loss: {rel_l2_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e52d00",
   "metadata": {},
   "source": [
    "# Model Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219321a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticFeatures(nn.Module):\n",
    "    def __init__(self, kernel, x_dim, num_features, prior = torch.nn.init.normal_):\n",
    "        super().__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.num_features = num_features\n",
    "        self.kernel = kernel\n",
    "        self.w = nn.Linear(x_dim, num_features, bias=False)\n",
    "        prior(self.w.weight)\n",
    "        self.w.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.kernel == \"trig\":\n",
    "            return  torch.sin(self.w(x))\n",
    "        elif self.kernel == \"trig symm\":\n",
    "            return  torch.cat([torch.sin(self.w(x)), torch.cos(self.w(x))], dim=-1)\n",
    "        elif self.kernel == \"relu\":\n",
    "            return  torch.nn.functional.relu(self.w(x))\n",
    "        else:\n",
    "            raise NotImplementedError(\"Fourier kernel is not implemented yet\")\n",
    "\n",
    "\n",
    "class ProjectionNets(nn.Module):\n",
    "    def __init__(self, x_dim, num_learned_basis, num_fixed_basis, learning_hidden_dim, activation = torch.nn.ReLU(), basis=None):\n",
    "        \"\"\"\n",
    "        x_dim: dimension of the input (10)\n",
    "        num_learned_basis: number of learned basis\n",
    "        learning_hidden_dim: width of hidden layers for the FNN\n",
    "        activation: activation function\n",
    "        num_fixed_basis: number of fixed basis\n",
    "        basis: a (B, input_dim) tensor of Fourier basis vectors. If None, we initialize randomly.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.num_learned_basis = num_learned_basis\n",
    "        self.learning_hidden_dim = learning_hidden_dim\n",
    "        self.activation = activation\n",
    "        self.num_fixed_basis = num_fixed_basis\n",
    "        self.basis = basis\n",
    "\n",
    "        # --- 1) define the FNN for the first A outputs ---\n",
    "        layers = [x_dim] + learning_hidden_dim + [num_learned_basis]\n",
    "        modules = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            modules.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            # add activation after every hidden layer, but not after the last Linear\n",
    "            if i < len(layers) - 2:\n",
    "                modules.append(activation)\n",
    "        self.fnn = nn.Sequential(*modules)\n",
    "\n",
    "        # --- 2) prepare the fixed basis ---\n",
    "        if basis is None:\n",
    "            self.basis = StochasticFeatures(kernel=\"trig\", x_dim=x_dim, num_features=num_fixed_basis)\n",
    "        else:\n",
    "            self.basis = basis\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: tensor of shape (..., x_dim)\n",
    "        returns: tensor of shape (..., num_learned_basis + num_fixed_basis)\n",
    "        \"\"\"\n",
    "        learned_out = self.fnn(x)              \n",
    "        fixed_out = self.basis(x)\n",
    "        return torch.cat([learned_out, fixed_out], dim=-1)\n",
    "\n",
    "def periodic(x):\n",
    "    y = 2 * torch.pi * x\n",
    "    return torch.cat(\n",
    "        [torch.cos(y), torch.sin(y), torch.cos(2 * y), torch.sin(2 * y)], -1\n",
    "    )\n",
    "\n",
    "\n",
    "class DeepONet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        x_dim = 1\n",
    "        y_dim = 2 * 4\n",
    "\n",
    "        self.branch_nets = nn.Sequential(\n",
    "            nn.Linear(128, 128), # coressponds to xi_i^k\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128), # coressponds to xi_i^k\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128), # coressponds to xi_i^k\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128), # coressponds to c_i^k \n",
    "        )\n",
    "\n",
    "        self.trunk_net = nn.Sequential(\n",
    "            nn.Linear(y_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, u, y):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "          x: Tensor of shape [B, L, 1], where B = batch size, L = number of integration points per sample.\n",
    "          u: Tensor of shape [B, L] (function values corresponding to x).\n",
    "        \"\"\"\n",
    "        u_flattened = torch.flatten(u, start_dim=-2)\n",
    "        branch_results = self.branch_nets(u_flattened)\n",
    "        z = periodic(y)\n",
    "        trunk_results = self.trunk_net(z)\n",
    "        results = (branch_results.unsqueeze(1) * trunk_results).sum(dim=-1, keepdim=True)\n",
    "        return results\n",
    "    \n",
    "    \n",
    "class BelNet(nn.Module):\n",
    "    def __init__(self, num_learned_basis = 50, num_fixed_basis = 50, basis = None):\n",
    "        super().__init__()\n",
    "        x_dim = 1\n",
    "        y_dim = 2 * 4\n",
    "        self.projection_nets = ProjectionNets(x_dim, num_learned_basis, num_fixed_basis, learning_hidden_dim=[64,64,64,64], activation=torch.nn.ReLU(), basis=basis)\n",
    "        self.branch_nets = nn.Sequential(\n",
    "            nn.Linear(num_learned_basis + num_fixed_basis, 100), # coressponds to xi_i^k\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100, 100), # coressponds to xi_i^k\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100, 100), # coressponds to xi_i^k\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100, 128), # coressponds to c_i^k \n",
    "        )\n",
    "\n",
    "        self.trunk_net = nn.Sequential(\n",
    "            nn.Linear(y_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, u, y):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "          x: Tensor of shape [B, L, 1], where B = batch size, L = number of integration points per sample.\n",
    "          u: Tensor of shape [B, L] (function values corresponding to x).\n",
    "        \"\"\"\n",
    "        B, L, _ = x.shape  # B: batch size, L: number of points\n",
    "        psi_outputs = self.projection_nets(x) # shape: [B, L, R]\n",
    "        psi_transpose = psi_outputs.transpose(1, 2)  # shape: [B, R, L]\n",
    "        proj_integration = (torch.bmm(psi_transpose, u) / float(L)).squeeze(-1) # shape: [B, R]\n",
    "        branch_results = self.branch_nets(proj_integration) # shape: [B, N]\n",
    "        z = periodic(y)\n",
    "        trunk_results = self.trunk_net(z)\n",
    "        results = (branch_results.unsqueeze(1) * trunk_results).sum(dim=-1, keepdim=True)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "080bcf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: torch.Size([1000, 128, 1]) torch.Size([1000, 128, 1]) torch.Size([1000, 1000, 2]) torch.Size([1000, 1000, 1])\n",
      "test shape: torch.Size([200, 128, 1]) torch.Size([200, 128, 1]) torch.Size([200, 1000, 2]) torch.Size([200, 1000, 1])\n",
      "Using examples 0\n",
      "Model has 100224 parameters\n",
      "Epoch [1/500000], Loss: 0.3985\n",
      "Validation Loss: 0.35323, mean Relative L2 Loss: 1.01816\n",
      "Epoch [5001/500000], Loss: 0.0194\n",
      "Validation Loss: 0.02008, mean Relative L2 Loss: 0.23530\n",
      "Epoch [10001/500000], Loss: 0.0214\n",
      "Validation Loss: 0.02327, mean Relative L2 Loss: 0.25198\n",
      "Epoch [15001/500000], Loss: 0.0131\n",
      "Validation Loss: 0.01380, mean Relative L2 Loss: 0.18625\n",
      "Epoch [20001/500000], Loss: 0.0117\n",
      "Validation Loss: 0.01268, mean Relative L2 Loss: 0.17623\n",
      "Epoch [25001/500000], Loss: 0.0126\n",
      "Validation Loss: 0.01353, mean Relative L2 Loss: 0.18349\n",
      "Epoch [30001/500000], Loss: 0.0084\n",
      "Validation Loss: 0.00914, mean Relative L2 Loss: 0.14280\n",
      "Epoch [35001/500000], Loss: 0.0084\n",
      "Validation Loss: 0.00923, mean Relative L2 Loss: 0.14403\n",
      "Epoch [40001/500000], Loss: 0.0117\n",
      "Validation Loss: 0.01244, mean Relative L2 Loss: 0.17576\n",
      "Epoch [45001/500000], Loss: 0.0071\n",
      "Validation Loss: 0.00772, mean Relative L2 Loss: 0.12945\n",
      "Epoch [50001/500000], Loss: 0.0071\n",
      "Validation Loss: 0.00770, mean Relative L2 Loss: 0.12938\n",
      "Epoch [55001/500000], Loss: 0.0067\n",
      "Validation Loss: 0.00731, mean Relative L2 Loss: 0.12531\n",
      "Epoch [60001/500000], Loss: 0.0070\n",
      "Validation Loss: 0.00775, mean Relative L2 Loss: 0.12965\n",
      "Epoch [65001/500000], Loss: 0.0068\n",
      "Validation Loss: 0.00750, mean Relative L2 Loss: 0.12744\n",
      "Epoch [70001/500000], Loss: 0.0065\n",
      "Validation Loss: 0.00721, mean Relative L2 Loss: 0.12408\n",
      "Epoch [75001/500000], Loss: 0.0049\n",
      "Validation Loss: 0.00571, mean Relative L2 Loss: 0.10472\n",
      "Epoch [80001/500000], Loss: 0.0050\n",
      "Validation Loss: 0.00570, mean Relative L2 Loss: 0.10517\n",
      "Epoch [85001/500000], Loss: 0.0057\n",
      "Validation Loss: 0.00658, mean Relative L2 Loss: 0.11573\n",
      "Epoch [90001/500000], Loss: 0.0042\n",
      "Validation Loss: 0.00500, mean Relative L2 Loss: 0.09584\n",
      "Epoch [95001/500000], Loss: 0.0047\n",
      "Validation Loss: 0.00591, mean Relative L2 Loss: 0.12162\n",
      "Epoch [100001/500000], Loss: 0.0050\n",
      "Validation Loss: 0.00597, mean Relative L2 Loss: 0.10786\n",
      "Epoch [105001/500000], Loss: 0.0039\n",
      "Validation Loss: 0.00482, mean Relative L2 Loss: 0.09320\n",
      "Epoch [110001/500000], Loss: 0.0040\n",
      "Validation Loss: 0.00497, mean Relative L2 Loss: 0.09933\n",
      "Epoch [115001/500000], Loss: 0.0049\n",
      "Validation Loss: 0.00588, mean Relative L2 Loss: 0.10712\n",
      "Epoch [120001/500000], Loss: 0.0036\n",
      "Validation Loss: 0.00444, mean Relative L2 Loss: 0.08856\n",
      "Epoch [125001/500000], Loss: 0.0035\n",
      "Validation Loss: 0.00434, mean Relative L2 Loss: 0.08740\n",
      "Epoch [130001/500000], Loss: 0.0036\n",
      "Validation Loss: 0.00449, mean Relative L2 Loss: 0.08950\n",
      "Epoch [135001/500000], Loss: 0.0031\n",
      "Validation Loss: 0.00385, mean Relative L2 Loss: 0.08051\n",
      "Epoch [140001/500000], Loss: 0.0032\n",
      "Validation Loss: 0.00397, mean Relative L2 Loss: 0.08248\n",
      "Epoch [145001/500000], Loss: 0.0032\n",
      "Validation Loss: 0.00409, mean Relative L2 Loss: 0.08390\n",
      "Epoch [150001/500000], Loss: 0.0032\n",
      "Validation Loss: 0.00411, mean Relative L2 Loss: 0.08395\n",
      "Epoch [155001/500000], Loss: 0.0034\n",
      "Validation Loss: 0.00429, mean Relative L2 Loss: 0.08709\n",
      "Epoch [160001/500000], Loss: 0.0029\n",
      "Validation Loss: 0.00358, mean Relative L2 Loss: 0.07733\n",
      "Epoch [165001/500000], Loss: 0.0029\n",
      "Validation Loss: 0.00359, mean Relative L2 Loss: 0.07715\n",
      "Epoch [170001/500000], Loss: 0.0028\n",
      "Validation Loss: 0.00353, mean Relative L2 Loss: 0.07716\n",
      "Epoch [175001/500000], Loss: 0.0027\n",
      "Validation Loss: 0.00344, mean Relative L2 Loss: 0.07548\n",
      "Epoch [180001/500000], Loss: 0.0028\n",
      "Validation Loss: 0.00357, mean Relative L2 Loss: 0.07717\n",
      "Epoch [185001/500000], Loss: 0.0029\n",
      "Validation Loss: 0.00360, mean Relative L2 Loss: 0.07811\n",
      "Epoch [190001/500000], Loss: 0.0025\n",
      "Validation Loss: 0.00326, mean Relative L2 Loss: 0.07251\n",
      "Epoch [195001/500000], Loss: 0.0027\n",
      "Validation Loss: 0.00340, mean Relative L2 Loss: 0.07439\n",
      "Epoch [200001/500000], Loss: 0.0025\n",
      "Validation Loss: 0.00323, mean Relative L2 Loss: 0.07178\n",
      "Epoch [205001/500000], Loss: 0.0026\n",
      "Validation Loss: 0.00344, mean Relative L2 Loss: 0.07767\n",
      "Epoch [210001/500000], Loss: 0.0032\n",
      "Validation Loss: 0.00398, mean Relative L2 Loss: 0.08409\n",
      "Epoch [215001/500000], Loss: 0.0024\n",
      "Validation Loss: 0.00311, mean Relative L2 Loss: 0.06977\n",
      "Epoch [220001/500000], Loss: 0.0025\n",
      "Validation Loss: 0.00326, mean Relative L2 Loss: 0.07266\n",
      "Epoch [225001/500000], Loss: 0.0023\n",
      "Validation Loss: 0.00308, mean Relative L2 Loss: 0.07014\n",
      "Epoch [230001/500000], Loss: 0.0024\n",
      "Validation Loss: 0.00312, mean Relative L2 Loss: 0.07053\n",
      "Epoch [235001/500000], Loss: 0.0024\n",
      "Validation Loss: 0.00316, mean Relative L2 Loss: 0.07113\n",
      "Epoch [240001/500000], Loss: 0.0022\n",
      "Validation Loss: 0.00298, mean Relative L2 Loss: 0.06769\n",
      "Epoch [245001/500000], Loss: 0.0023\n",
      "Validation Loss: 0.00306, mean Relative L2 Loss: 0.06896\n",
      "Epoch [250001/500000], Loss: 0.0022\n",
      "Validation Loss: 0.00292, mean Relative L2 Loss: 0.06718\n",
      "Epoch [255001/500000], Loss: 0.0022\n",
      "Validation Loss: 0.00291, mean Relative L2 Loss: 0.06672\n",
      "Epoch [260001/500000], Loss: 0.0024\n",
      "Validation Loss: 0.00326, mean Relative L2 Loss: 0.07187\n",
      "Epoch [265001/500000], Loss: 0.0021\n",
      "Validation Loss: 0.00285, mean Relative L2 Loss: 0.06571\n",
      "Epoch [270001/500000], Loss: 0.0021\n",
      "Validation Loss: 0.00280, mean Relative L2 Loss: 0.06585\n",
      "Epoch [275001/500000], Loss: 0.0022\n",
      "Validation Loss: 0.00293, mean Relative L2 Loss: 0.06876\n",
      "Epoch [280001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00277, mean Relative L2 Loss: 0.06456\n",
      "Epoch [285001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00275, mean Relative L2 Loss: 0.06397\n",
      "Epoch [290001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00279, mean Relative L2 Loss: 0.06479\n",
      "Epoch [295001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00279, mean Relative L2 Loss: 0.06436\n",
      "Epoch [300001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00277, mean Relative L2 Loss: 0.06463\n",
      "Epoch [305001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00277, mean Relative L2 Loss: 0.06404\n",
      "Epoch [310001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00277, mean Relative L2 Loss: 0.06422\n",
      "Epoch [315001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00275, mean Relative L2 Loss: 0.06390\n",
      "Epoch [320001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00274, mean Relative L2 Loss: 0.06348\n",
      "Epoch [325001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00273, mean Relative L2 Loss: 0.06326\n",
      "Epoch [330001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00287, mean Relative L2 Loss: 0.06532\n",
      "Epoch [335001/500000], Loss: 0.0018\n",
      "Validation Loss: 0.00270, mean Relative L2 Loss: 0.06250\n",
      "Epoch [340001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00274, mean Relative L2 Loss: 0.06350\n",
      "Epoch [345001/500000], Loss: 0.0018\n",
      "Validation Loss: 0.00267, mean Relative L2 Loss: 0.06190\n",
      "Epoch [350001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00283, mean Relative L2 Loss: 0.06532\n",
      "Epoch [355001/500000], Loss: 0.0018\n",
      "Validation Loss: 0.00268, mean Relative L2 Loss: 0.06258\n",
      "Epoch [360001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00276, mean Relative L2 Loss: 0.06374\n",
      "Epoch [365001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00264, mean Relative L2 Loss: 0.06105\n",
      "Epoch [370001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00265, mean Relative L2 Loss: 0.06102\n",
      "Epoch [375001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00266, mean Relative L2 Loss: 0.06135\n",
      "Epoch [380001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00265, mean Relative L2 Loss: 0.06082\n",
      "Epoch [385001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00265, mean Relative L2 Loss: 0.06064\n",
      "Epoch [390001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00264, mean Relative L2 Loss: 0.06051\n",
      "Epoch [395001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00262, mean Relative L2 Loss: 0.05999\n",
      "Epoch [400001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00262, mean Relative L2 Loss: 0.05946\n",
      "Epoch [405001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00261, mean Relative L2 Loss: 0.05952\n",
      "Epoch [410001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00261, mean Relative L2 Loss: 0.05910\n",
      "Epoch [415001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00260, mean Relative L2 Loss: 0.05882\n",
      "Epoch [420001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00261, mean Relative L2 Loss: 0.05874\n",
      "Epoch [425001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00261, mean Relative L2 Loss: 0.05863\n",
      "Epoch [430001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00262, mean Relative L2 Loss: 0.05869\n",
      "Epoch [435001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00261, mean Relative L2 Loss: 0.05854\n",
      "Epoch [440001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00263, mean Relative L2 Loss: 0.05890\n",
      "Epoch [445001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00263, mean Relative L2 Loss: 0.05861\n",
      "Epoch [450001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00263, mean Relative L2 Loss: 0.05854\n",
      "Epoch [455001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00263, mean Relative L2 Loss: 0.05861\n",
      "Epoch [460001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00265, mean Relative L2 Loss: 0.05906\n",
      "Epoch [465001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00265, mean Relative L2 Loss: 0.05876\n",
      "Epoch [470001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00265, mean Relative L2 Loss: 0.05856\n",
      "Epoch [475001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00265, mean Relative L2 Loss: 0.05854\n",
      "Epoch [480001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00266, mean Relative L2 Loss: 0.05864\n",
      "Epoch [485001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00266, mean Relative L2 Loss: 0.05850\n",
      "Epoch [490001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00268, mean Relative L2 Loss: 0.05879\n",
      "Epoch [495001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00268, mean Relative L2 Loss: 0.05861\n",
      "Example 0 finished training, final error is: \n",
      "Validation Loss: 0.00269, mean Relative L2 Loss: 0.05866\n",
      "Using examples 1\n",
      "Model has 88262 parameters\n",
      "Epoch [1/500000], Loss: 0.3636\n",
      "Validation Loss: 0.37458, mean Relative L2 Loss: 1.07825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5001/500000], Loss: 0.0353\n",
      "Validation Loss: 0.03562, mean Relative L2 Loss: 0.32972\n",
      "Epoch [10001/500000], Loss: 0.0352\n",
      "Validation Loss: 0.03556, mean Relative L2 Loss: 0.32938\n",
      "Epoch [15001/500000], Loss: 0.0274\n",
      "Validation Loss: 0.02890, mean Relative L2 Loss: 0.29040\n",
      "Epoch [20001/500000], Loss: 0.0299\n",
      "Validation Loss: 0.03059, mean Relative L2 Loss: 0.30012\n",
      "Epoch [25001/500000], Loss: 0.0201\n",
      "Validation Loss: 0.02072, mean Relative L2 Loss: 0.24001\n",
      "Epoch [30001/500000], Loss: 0.0367\n",
      "Validation Loss: 0.03739, mean Relative L2 Loss: 0.33671\n",
      "Epoch [35001/500000], Loss: 0.0165\n",
      "Validation Loss: 0.01698, mean Relative L2 Loss: 0.21231\n",
      "Epoch [40001/500000], Loss: 0.0168\n",
      "Validation Loss: 0.01723, mean Relative L2 Loss: 0.21316\n",
      "Epoch [45001/500000], Loss: 0.0363\n",
      "Validation Loss: 0.03786, mean Relative L2 Loss: 0.33648\n",
      "Epoch [50001/500000], Loss: 0.0169\n",
      "Validation Loss: 0.01747, mean Relative L2 Loss: 0.21746\n",
      "Epoch [55001/500000], Loss: 0.0341\n",
      "Validation Loss: 0.03499, mean Relative L2 Loss: 0.32500\n",
      "Epoch [60001/500000], Loss: 0.0173\n",
      "Validation Loss: 0.01729, mean Relative L2 Loss: 0.21497\n",
      "Epoch [65001/500000], Loss: 0.0206\n",
      "Validation Loss: 0.02257, mean Relative L2 Loss: 0.24818\n",
      "Epoch [70001/500000], Loss: 0.0162\n",
      "Validation Loss: 0.01667, mean Relative L2 Loss: 0.21024\n",
      "Epoch [75001/500000], Loss: 0.0200\n",
      "Validation Loss: 0.02077, mean Relative L2 Loss: 0.23899\n",
      "Epoch [80001/500000], Loss: 0.0131\n",
      "Validation Loss: 0.01365, mean Relative L2 Loss: 0.18575\n",
      "Epoch [85001/500000], Loss: 0.0131\n",
      "Validation Loss: 0.01364, mean Relative L2 Loss: 0.18582\n",
      "Epoch [90001/500000], Loss: 0.2496\n",
      "Validation Loss: 0.19929, mean Relative L2 Loss: 0.83083\n",
      "Epoch [95001/500000], Loss: 0.0112\n",
      "Validation Loss: 0.01205, mean Relative L2 Loss: 0.17095\n",
      "Epoch [100001/500000], Loss: 0.0094\n",
      "Validation Loss: 0.01009, mean Relative L2 Loss: 0.15211\n",
      "Epoch [105001/500000], Loss: 0.0112\n",
      "Validation Loss: 0.01181, mean Relative L2 Loss: 0.16839\n",
      "Epoch [110001/500000], Loss: 0.0156\n",
      "Validation Loss: 0.01612, mean Relative L2 Loss: 0.20518\n",
      "Epoch [115001/500000], Loss: 0.0094\n",
      "Validation Loss: 0.01008, mean Relative L2 Loss: 0.15216\n",
      "Epoch [120001/500000], Loss: 0.0109\n",
      "Validation Loss: 0.01154, mean Relative L2 Loss: 0.16661\n",
      "Epoch [125001/500000], Loss: 0.0083\n",
      "Validation Loss: 0.00881, mean Relative L2 Loss: 0.14146\n",
      "Epoch [135001/500000], Loss: 0.0082\n",
      "Validation Loss: 0.00877, mean Relative L2 Loss: 0.14082\n",
      "Epoch [140001/500000], Loss: 0.0104\n",
      "Validation Loss: 0.01073, mean Relative L2 Loss: 0.16183\n",
      "Epoch [145001/500000], Loss: 0.0075\n",
      "Validation Loss: 0.00813, mean Relative L2 Loss: 0.13460\n",
      "Epoch [150001/500000], Loss: 0.0082\n",
      "Validation Loss: 0.00876, mean Relative L2 Loss: 0.14156\n",
      "Epoch [155001/500000], Loss: 0.0072\n",
      "Validation Loss: 0.00779, mean Relative L2 Loss: 0.13120\n",
      "Epoch [160001/500000], Loss: 0.0076\n",
      "Validation Loss: 0.00815, mean Relative L2 Loss: 0.13494\n",
      "Epoch [165001/500000], Loss: 0.0167\n",
      "Validation Loss: 0.01726, mean Relative L2 Loss: 0.21802\n",
      "Epoch [170001/500000], Loss: 0.0070\n",
      "Validation Loss: 0.00762, mean Relative L2 Loss: 0.12892\n",
      "Epoch [175001/500000], Loss: 0.0090\n",
      "Validation Loss: 0.00968, mean Relative L2 Loss: 0.15163\n",
      "Epoch [180001/500000], Loss: 0.0066\n",
      "Validation Loss: 0.00729, mean Relative L2 Loss: 0.12530\n",
      "Epoch [185001/500000], Loss: 0.0078\n",
      "Validation Loss: 0.00840, mean Relative L2 Loss: 0.13815\n",
      "Epoch [190001/500000], Loss: 0.0063\n",
      "Validation Loss: 0.00700, mean Relative L2 Loss: 0.12217\n",
      "Epoch [195001/500000], Loss: 0.0065\n",
      "Validation Loss: 0.00721, mean Relative L2 Loss: 0.12440\n",
      "Epoch [200001/500000], Loss: 0.0062\n",
      "Validation Loss: 0.00690, mean Relative L2 Loss: 0.12117\n",
      "Epoch [205001/500000], Loss: 0.0071\n",
      "Validation Loss: 0.00775, mean Relative L2 Loss: 0.13040\n",
      "Epoch [210001/500000], Loss: 0.0062\n",
      "Validation Loss: 0.00702, mean Relative L2 Loss: 0.12277\n",
      "Epoch [215001/500000], Loss: 0.0062\n",
      "Validation Loss: 0.00692, mean Relative L2 Loss: 0.12160\n",
      "Epoch [220001/500000], Loss: 0.0057\n",
      "Validation Loss: 0.00647, mean Relative L2 Loss: 0.11533\n",
      "Epoch [225001/500000], Loss: 0.0064\n",
      "Validation Loss: 0.00706, mean Relative L2 Loss: 0.12348\n",
      "Epoch [230001/500000], Loss: 0.0056\n",
      "Validation Loss: 0.00642, mean Relative L2 Loss: 0.11489\n",
      "Epoch [235001/500000], Loss: 0.0062\n",
      "Validation Loss: 0.00685, mean Relative L2 Loss: 0.12118\n",
      "Epoch [240001/500000], Loss: 0.0055\n",
      "Validation Loss: 0.00624, mean Relative L2 Loss: 0.11236\n",
      "Epoch [245001/500000], Loss: 0.0059\n",
      "Validation Loss: 0.00665, mean Relative L2 Loss: 0.11837\n",
      "Epoch [250001/500000], Loss: 0.0054\n",
      "Validation Loss: 0.00620, mean Relative L2 Loss: 0.11199\n",
      "Epoch [255001/500000], Loss: 0.0059\n",
      "Validation Loss: 0.00670, mean Relative L2 Loss: 0.11874\n",
      "Epoch [260001/500000], Loss: 0.0051\n",
      "Validation Loss: 0.00575, mean Relative L2 Loss: 0.10672\n",
      "Epoch [265001/500000], Loss: 0.0055\n",
      "Validation Loss: 0.00623, mean Relative L2 Loss: 0.11329\n",
      "Epoch [270001/500000], Loss: 0.0050\n",
      "Validation Loss: 0.00571, mean Relative L2 Loss: 0.10623\n",
      "Epoch [275001/500000], Loss: 0.0056\n",
      "Validation Loss: 0.00629, mean Relative L2 Loss: 0.11357\n",
      "Epoch [280001/500000], Loss: 0.0049\n",
      "Validation Loss: 0.00560, mean Relative L2 Loss: 0.10428\n",
      "Epoch [285001/500000], Loss: 0.0056\n",
      "Validation Loss: 0.00624, mean Relative L2 Loss: 0.11316\n",
      "Epoch [290001/500000], Loss: 0.0049\n",
      "Validation Loss: 0.00559, mean Relative L2 Loss: 0.10412\n",
      "Epoch [295001/500000], Loss: 0.0053\n",
      "Validation Loss: 0.00599, mean Relative L2 Loss: 0.10957\n",
      "Epoch [300001/500000], Loss: 0.0047\n",
      "Validation Loss: 0.00546, mean Relative L2 Loss: 0.10272\n",
      "Epoch [305001/500000], Loss: 0.0051\n",
      "Validation Loss: 0.00577, mean Relative L2 Loss: 0.10687\n",
      "Epoch [310001/500000], Loss: 0.0045\n",
      "Validation Loss: 0.00527, mean Relative L2 Loss: 0.10044\n",
      "Epoch [315001/500000], Loss: 0.0048\n",
      "Validation Loss: 0.00555, mean Relative L2 Loss: 0.10391\n",
      "Epoch [320001/500000], Loss: 0.0044\n",
      "Validation Loss: 0.00520, mean Relative L2 Loss: 0.09904\n",
      "Epoch [325001/500000], Loss: 0.0047\n",
      "Validation Loss: 0.00547, mean Relative L2 Loss: 0.10243\n",
      "Epoch [330001/500000], Loss: 0.0043\n",
      "Validation Loss: 0.00517, mean Relative L2 Loss: 0.09821\n",
      "Epoch [335001/500000], Loss: 0.0045\n",
      "Validation Loss: 0.00538, mean Relative L2 Loss: 0.10128\n",
      "Epoch [340001/500000], Loss: 0.0044\n",
      "Validation Loss: 0.00531, mean Relative L2 Loss: 0.10150\n",
      "Epoch [345001/500000], Loss: 0.0043\n",
      "Validation Loss: 0.00523, mean Relative L2 Loss: 0.09932\n",
      "Epoch [350001/500000], Loss: 0.0041\n",
      "Validation Loss: 0.00494, mean Relative L2 Loss: 0.09487\n",
      "Epoch [355001/500000], Loss: 0.0043\n",
      "Validation Loss: 0.00519, mean Relative L2 Loss: 0.09820\n",
      "Epoch [360001/500000], Loss: 0.0040\n",
      "Validation Loss: 0.00493, mean Relative L2 Loss: 0.09466\n",
      "Epoch [365001/500000], Loss: 0.0043\n",
      "Validation Loss: 0.00516, mean Relative L2 Loss: 0.09787\n",
      "Epoch [370001/500000], Loss: 0.0041\n",
      "Validation Loss: 0.00496, mean Relative L2 Loss: 0.09556\n",
      "Epoch [375001/500000], Loss: 0.0041\n",
      "Validation Loss: 0.00502, mean Relative L2 Loss: 0.09603\n",
      "Epoch [380001/500000], Loss: 0.0039\n",
      "Validation Loss: 0.00486, mean Relative L2 Loss: 0.09378\n",
      "Epoch [385001/500000], Loss: 0.0041\n",
      "Validation Loss: 0.00507, mean Relative L2 Loss: 0.09638\n",
      "Epoch [390001/500000], Loss: 0.0040\n",
      "Validation Loss: 0.00492, mean Relative L2 Loss: 0.09457\n",
      "Epoch [395001/500000], Loss: 0.0043\n",
      "Validation Loss: 0.00525, mean Relative L2 Loss: 0.09872\n",
      "Epoch [400001/500000], Loss: 0.0039\n",
      "Validation Loss: 0.00487, mean Relative L2 Loss: 0.09400\n",
      "Epoch [405001/500000], Loss: 0.0070\n",
      "Validation Loss: 0.00773, mean Relative L2 Loss: 0.13239\n",
      "Epoch [410001/500000], Loss: 0.0039\n",
      "Validation Loss: 0.00490, mean Relative L2 Loss: 0.09392\n",
      "Epoch [415001/500000], Loss: 0.0039\n",
      "Validation Loss: 0.00485, mean Relative L2 Loss: 0.09329\n",
      "Epoch [420001/500000], Loss: 0.0040\n",
      "Validation Loss: 0.00496, mean Relative L2 Loss: 0.09473\n",
      "Epoch [425001/500000], Loss: 0.0038\n",
      "Validation Loss: 0.00485, mean Relative L2 Loss: 0.09315\n",
      "Epoch [430001/500000], Loss: 0.0040\n",
      "Validation Loss: 0.00508, mean Relative L2 Loss: 0.09644\n",
      "Epoch [435001/500000], Loss: 0.0038\n",
      "Validation Loss: 0.00484, mean Relative L2 Loss: 0.09290\n",
      "Epoch [440001/500000], Loss: 0.0043\n",
      "Validation Loss: 0.00535, mean Relative L2 Loss: 0.10021\n",
      "Epoch [445001/500000], Loss: 0.0037\n",
      "Validation Loss: 0.00481, mean Relative L2 Loss: 0.09300\n",
      "Epoch [450001/500000], Loss: 0.0036\n",
      "Validation Loss: 0.00474, mean Relative L2 Loss: 0.09211\n",
      "Epoch [455001/500000], Loss: 0.0036\n",
      "Validation Loss: 0.00474, mean Relative L2 Loss: 0.09208\n",
      "Epoch [460001/500000], Loss: 0.0290\n",
      "Validation Loss: 0.03164, mean Relative L2 Loss: 0.28736\n",
      "Epoch [465001/500000], Loss: 0.0036\n",
      "Validation Loss: 0.00472, mean Relative L2 Loss: 0.09163\n",
      "Epoch [470001/500000], Loss: 0.0037\n",
      "Validation Loss: 0.00489, mean Relative L2 Loss: 0.09386\n",
      "Epoch [475001/500000], Loss: 0.0036\n",
      "Validation Loss: 0.00474, mean Relative L2 Loss: 0.09192\n",
      "Epoch [480001/500000], Loss: 0.0129\n",
      "Validation Loss: 0.01332, mean Relative L2 Loss: 0.18769\n",
      "Epoch [485001/500000], Loss: 0.0035\n",
      "Validation Loss: 0.00469, mean Relative L2 Loss: 0.09085\n",
      "Epoch [490001/500000], Loss: 0.0035\n",
      "Validation Loss: 0.00468, mean Relative L2 Loss: 0.09082\n",
      "Epoch [495001/500000], Loss: 0.0035\n",
      "Validation Loss: 0.00467, mean Relative L2 Loss: 0.09054\n",
      "Example 1 finished training, final error is: \n",
      "Validation Loss: 0.00479, mean Relative L2 Loss: 0.09338\n",
      "Using examples 2\n",
      "torch.Size([30, 1])\n",
      "Model has 94262 parameters\n",
      "Epoch [1/500000], Loss: 0.3593\n",
      "Validation Loss: 0.35933, mean Relative L2 Loss: 1.03681\n",
      "Epoch [5001/500000], Loss: 0.0142\n",
      "Validation Loss: 0.01481, mean Relative L2 Loss: 0.19562\n",
      "Epoch [10001/500000], Loss: 0.0115\n",
      "Validation Loss: 0.01160, mean Relative L2 Loss: 0.16769\n",
      "Epoch [15001/500000], Loss: 0.0075\n",
      "Validation Loss: 0.00801, mean Relative L2 Loss: 0.13262\n",
      "Epoch [20001/500000], Loss: 0.0062\n",
      "Validation Loss: 0.00694, mean Relative L2 Loss: 0.11963\n",
      "Epoch [25001/500000], Loss: 0.0053\n",
      "Validation Loss: 0.00595, mean Relative L2 Loss: 0.10798\n",
      "Epoch [30001/500000], Loss: 0.0043\n",
      "Validation Loss: 0.00507, mean Relative L2 Loss: 0.09740\n",
      "Epoch [35001/500000], Loss: 0.0038\n",
      "Validation Loss: 0.00453, mean Relative L2 Loss: 0.08968\n",
      "Epoch [40001/500000], Loss: 0.0034\n",
      "Validation Loss: 0.00426, mean Relative L2 Loss: 0.08521\n",
      "Epoch [45001/500000], Loss: 0.0031\n",
      "Validation Loss: 0.00390, mean Relative L2 Loss: 0.07992\n",
      "Epoch [50001/500000], Loss: 0.0029\n",
      "Validation Loss: 0.00376, mean Relative L2 Loss: 0.07747\n",
      "Epoch [55001/500000], Loss: 0.0028\n",
      "Validation Loss: 0.00367, mean Relative L2 Loss: 0.07622\n",
      "Epoch [60001/500000], Loss: 0.0025\n",
      "Validation Loss: 0.00351, mean Relative L2 Loss: 0.07254\n",
      "Epoch [65001/500000], Loss: 0.0024\n",
      "Validation Loss: 0.00343, mean Relative L2 Loss: 0.07088\n",
      "Epoch [70001/500000], Loss: 0.0023\n",
      "Validation Loss: 0.00333, mean Relative L2 Loss: 0.06894\n",
      "Epoch [75001/500000], Loss: 0.0023\n",
      "Validation Loss: 0.00336, mean Relative L2 Loss: 0.06914\n",
      "Epoch [80001/500000], Loss: 0.0021\n",
      "Validation Loss: 0.00328, mean Relative L2 Loss: 0.06626\n",
      "Epoch [85001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00334, mean Relative L2 Loss: 0.06597\n",
      "Epoch [90001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00337, mean Relative L2 Loss: 0.06486\n",
      "Epoch [95001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00338, mean Relative L2 Loss: 0.06506\n",
      "Epoch [100001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00339, mean Relative L2 Loss: 0.06425\n",
      "Epoch [105001/500000], Loss: 0.0018\n",
      "Validation Loss: 0.00338, mean Relative L2 Loss: 0.06332\n",
      "Epoch [110001/500000], Loss: 0.0018\n",
      "Validation Loss: 0.00336, mean Relative L2 Loss: 0.06256\n",
      "Epoch [115001/500000], Loss: 0.0018\n",
      "Validation Loss: 0.00337, mean Relative L2 Loss: 0.06250\n",
      "Epoch [120001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00349, mean Relative L2 Loss: 0.06396\n",
      "Epoch [125001/500000], Loss: 0.0018\n",
      "Validation Loss: 0.00339, mean Relative L2 Loss: 0.06207\n",
      "Epoch [130001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00343, mean Relative L2 Loss: 0.06186\n",
      "Epoch [135001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00345, mean Relative L2 Loss: 0.06128\n",
      "Epoch [140001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00346, mean Relative L2 Loss: 0.06115\n",
      "Epoch [145001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00349, mean Relative L2 Loss: 0.06131\n",
      "Epoch [150001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00352, mean Relative L2 Loss: 0.06132\n",
      "Epoch [155001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00357, mean Relative L2 Loss: 0.06117\n",
      "Epoch [160001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00359, mean Relative L2 Loss: 0.06131\n",
      "Epoch [165001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00366, mean Relative L2 Loss: 0.06131\n",
      "Epoch [170001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00373, mean Relative L2 Loss: 0.06151\n",
      "Epoch [175001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00366, mean Relative L2 Loss: 0.06021\n",
      "Epoch [180001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00367, mean Relative L2 Loss: 0.06015\n",
      "Epoch [185001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00370, mean Relative L2 Loss: 0.05977\n",
      "Epoch [190001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00372, mean Relative L2 Loss: 0.05991\n",
      "Epoch [195001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00375, mean Relative L2 Loss: 0.05962\n",
      "Epoch [200001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00378, mean Relative L2 Loss: 0.05990\n",
      "Epoch [205001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00377, mean Relative L2 Loss: 0.05936\n",
      "Epoch [210001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00378, mean Relative L2 Loss: 0.05972\n",
      "Epoch [215001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00383, mean Relative L2 Loss: 0.05986\n",
      "Epoch [220001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00377, mean Relative L2 Loss: 0.05915\n",
      "Epoch [225001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00379, mean Relative L2 Loss: 0.05918\n",
      "Epoch [230001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00377, mean Relative L2 Loss: 0.05914\n",
      "Epoch [235001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00378, mean Relative L2 Loss: 0.05864\n",
      "Epoch [240001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00378, mean Relative L2 Loss: 0.05856\n",
      "Epoch [245001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00382, mean Relative L2 Loss: 0.05943\n",
      "Epoch [250001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00382, mean Relative L2 Loss: 0.05870\n",
      "Epoch [255001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00381, mean Relative L2 Loss: 0.05892\n",
      "Epoch [260001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00384, mean Relative L2 Loss: 0.05851\n",
      "Epoch [265001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00385, mean Relative L2 Loss: 0.05867\n",
      "Epoch [270001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00388, mean Relative L2 Loss: 0.05868\n",
      "Epoch [275001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00392, mean Relative L2 Loss: 0.05880\n",
      "Epoch [280001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00390, mean Relative L2 Loss: 0.05853\n",
      "Epoch [285001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00394, mean Relative L2 Loss: 0.05853\n",
      "Epoch [290001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00397, mean Relative L2 Loss: 0.05866\n",
      "Epoch [295001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00398, mean Relative L2 Loss: 0.05855\n",
      "Epoch [300001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00401, mean Relative L2 Loss: 0.05870\n",
      "Epoch [305001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00402, mean Relative L2 Loss: 0.05870\n",
      "Epoch [310001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00403, mean Relative L2 Loss: 0.05855\n",
      "Epoch [315001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00405, mean Relative L2 Loss: 0.05873\n",
      "Epoch [320001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00409, mean Relative L2 Loss: 0.05868\n",
      "Epoch [325001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00410, mean Relative L2 Loss: 0.05884\n",
      "Epoch [330001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00410, mean Relative L2 Loss: 0.05866\n",
      "Epoch [335001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00413, mean Relative L2 Loss: 0.05875\n",
      "Epoch [340001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00417, mean Relative L2 Loss: 0.05872\n",
      "Epoch [345001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00417, mean Relative L2 Loss: 0.05866\n",
      "Epoch [350001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00416, mean Relative L2 Loss: 0.05891\n",
      "Epoch [355001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00423, mean Relative L2 Loss: 0.05904\n",
      "Epoch [360001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00423, mean Relative L2 Loss: 0.05900\n",
      "Epoch [365001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00424, mean Relative L2 Loss: 0.05870\n",
      "Epoch [370001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00424, mean Relative L2 Loss: 0.05888\n",
      "Epoch [375001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00425, mean Relative L2 Loss: 0.05861\n",
      "Epoch [380001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00428, mean Relative L2 Loss: 0.05862\n",
      "Epoch [385001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00427, mean Relative L2 Loss: 0.05854\n",
      "Epoch [390001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00430, mean Relative L2 Loss: 0.05848\n",
      "Epoch [395001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00431, mean Relative L2 Loss: 0.05857\n",
      "Epoch [400001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00433, mean Relative L2 Loss: 0.05847\n",
      "Epoch [405001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00436, mean Relative L2 Loss: 0.05844\n",
      "Epoch [410001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00437, mean Relative L2 Loss: 0.05841\n",
      "Epoch [415001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00439, mean Relative L2 Loss: 0.05844\n",
      "Epoch [420001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00440, mean Relative L2 Loss: 0.05837\n",
      "Epoch [425001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00442, mean Relative L2 Loss: 0.05841\n",
      "Epoch [430001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00442, mean Relative L2 Loss: 0.05834\n",
      "Epoch [435001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00444, mean Relative L2 Loss: 0.05843\n",
      "Epoch [440001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00445, mean Relative L2 Loss: 0.05830\n",
      "Epoch [445001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00445, mean Relative L2 Loss: 0.05818\n",
      "Epoch [450001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00449, mean Relative L2 Loss: 0.05839\n",
      "Epoch [455001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00446, mean Relative L2 Loss: 0.05841\n",
      "Epoch [460001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00448, mean Relative L2 Loss: 0.05810\n",
      "Epoch [465001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00449, mean Relative L2 Loss: 0.05796\n",
      "Epoch [470001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00448, mean Relative L2 Loss: 0.05792\n",
      "Epoch [475001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00451, mean Relative L2 Loss: 0.05790\n",
      "Epoch [480001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00455, mean Relative L2 Loss: 0.05831\n",
      "Epoch [485001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00455, mean Relative L2 Loss: 0.05797\n",
      "Epoch [490001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00454, mean Relative L2 Loss: 0.05799\n",
      "Epoch [495001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00456, mean Relative L2 Loss: 0.05791\n",
      "Example 2 finished training, final error is: \n",
      "Validation Loss: 0.00456, mean Relative L2 Loss: 0.05773\n",
      "Using examples 3\n",
      "torch.Size([30, 1])\n",
      "Model has 86012 parameters\n",
      "Epoch [1/500000], Loss: 0.3607\n",
      "Validation Loss: 0.37492, mean Relative L2 Loss: 1.08133\n",
      "Epoch [5001/500000], Loss: 0.0145\n",
      "Validation Loss: 0.01518, mean Relative L2 Loss: 0.19977\n",
      "Epoch [10001/500000], Loss: 0.0099\n",
      "Validation Loss: 0.01056, mean Relative L2 Loss: 0.15806\n",
      "Epoch [15001/500000], Loss: 0.0073\n",
      "Validation Loss: 0.00789, mean Relative L2 Loss: 0.13202\n",
      "Epoch [20001/500000], Loss: 0.0059\n",
      "Validation Loss: 0.00658, mean Relative L2 Loss: 0.11766\n",
      "Epoch [25001/500000], Loss: 0.0047\n",
      "Validation Loss: 0.00526, mean Relative L2 Loss: 0.10019\n",
      "Epoch [30001/500000], Loss: 0.0039\n",
      "Validation Loss: 0.00468, mean Relative L2 Loss: 0.09180\n",
      "Epoch [35001/500000], Loss: 0.0033\n",
      "Validation Loss: 0.00405, mean Relative L2 Loss: 0.08344\n",
      "Epoch [40001/500000], Loss: 0.0030\n",
      "Validation Loss: 0.00366, mean Relative L2 Loss: 0.07847\n",
      "Epoch [45001/500000], Loss: 0.0029\n",
      "Validation Loss: 0.00348, mean Relative L2 Loss: 0.07715\n",
      "Epoch [50001/500000], Loss: 0.0027\n",
      "Validation Loss: 0.00317, mean Relative L2 Loss: 0.07128\n",
      "Epoch [55001/500000], Loss: 0.0024\n",
      "Validation Loss: 0.00304, mean Relative L2 Loss: 0.06851\n",
      "Epoch [60001/500000], Loss: 0.0023\n",
      "Validation Loss: 0.00298, mean Relative L2 Loss: 0.06749\n",
      "Epoch [65001/500000], Loss: 0.0024\n",
      "Validation Loss: 0.00310, mean Relative L2 Loss: 0.06914\n",
      "Epoch [70001/500000], Loss: 0.0023\n",
      "Validation Loss: 0.00309, mean Relative L2 Loss: 0.06950\n",
      "Epoch [75001/500000], Loss: 0.0021\n",
      "Validation Loss: 0.00286, mean Relative L2 Loss: 0.06484\n",
      "Epoch [80001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00279, mean Relative L2 Loss: 0.06364\n",
      "Epoch [85001/500000], Loss: 0.0020\n",
      "Validation Loss: 0.00276, mean Relative L2 Loss: 0.06281\n",
      "Epoch [90001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00269, mean Relative L2 Loss: 0.06181\n",
      "Epoch [95001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00266, mean Relative L2 Loss: 0.06137\n",
      "Epoch [100001/500000], Loss: 0.0019\n",
      "Validation Loss: 0.00267, mean Relative L2 Loss: 0.06164\n",
      "Epoch [105001/500000], Loss: 0.0018\n",
      "Validation Loss: 0.00261, mean Relative L2 Loss: 0.06053\n",
      "Epoch [110001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00257, mean Relative L2 Loss: 0.05952\n",
      "Epoch [115001/500000], Loss: 0.0018\n",
      "Validation Loss: 0.00264, mean Relative L2 Loss: 0.06102\n",
      "Epoch [120001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00253, mean Relative L2 Loss: 0.05874\n",
      "Epoch [125001/500000], Loss: 0.0017\n",
      "Validation Loss: 0.00257, mean Relative L2 Loss: 0.06008\n",
      "Epoch [130001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00250, mean Relative L2 Loss: 0.05773\n",
      "Epoch [135001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00249, mean Relative L2 Loss: 0.05740\n",
      "Epoch [140001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00249, mean Relative L2 Loss: 0.05728\n",
      "Epoch [145001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00253, mean Relative L2 Loss: 0.05795\n",
      "Epoch [150001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00248, mean Relative L2 Loss: 0.05697\n",
      "Epoch [155001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00249, mean Relative L2 Loss: 0.05695\n",
      "Epoch [160001/500000], Loss: 0.0016\n",
      "Validation Loss: 0.00256, mean Relative L2 Loss: 0.05827\n",
      "Epoch [165001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00248, mean Relative L2 Loss: 0.05647\n",
      "Epoch [170001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00248, mean Relative L2 Loss: 0.05639\n",
      "Epoch [175001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00250, mean Relative L2 Loss: 0.05675\n",
      "Epoch [180001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00253, mean Relative L2 Loss: 0.05718\n",
      "Epoch [185001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00247, mean Relative L2 Loss: 0.05570\n",
      "Epoch [190001/500000], Loss: 0.0015\n",
      "Validation Loss: 0.00251, mean Relative L2 Loss: 0.05644\n",
      "Epoch [195001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00246, mean Relative L2 Loss: 0.05535\n",
      "Epoch [200001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00246, mean Relative L2 Loss: 0.05533\n",
      "Epoch [205001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00247, mean Relative L2 Loss: 0.05562\n",
      "Epoch [210001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00248, mean Relative L2 Loss: 0.05571\n",
      "Epoch [215001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00245, mean Relative L2 Loss: 0.05478\n",
      "Epoch [220001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00244, mean Relative L2 Loss: 0.05473\n",
      "Epoch [225001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00246, mean Relative L2 Loss: 0.05528\n",
      "Epoch [230001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00243, mean Relative L2 Loss: 0.05444\n",
      "Epoch [235001/500000], Loss: 0.0014\n",
      "Validation Loss: 0.00246, mean Relative L2 Loss: 0.05502\n",
      "Epoch [240001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00242, mean Relative L2 Loss: 0.05419\n",
      "Epoch [245001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00241, mean Relative L2 Loss: 0.05396\n",
      "Epoch [250001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00241, mean Relative L2 Loss: 0.05413\n",
      "Epoch [255001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00240, mean Relative L2 Loss: 0.05376\n",
      "Epoch [260001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00240, mean Relative L2 Loss: 0.05382\n",
      "Epoch [265001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00239, mean Relative L2 Loss: 0.05359\n",
      "Epoch [270001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00240, mean Relative L2 Loss: 0.05378\n",
      "Epoch [275001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00240, mean Relative L2 Loss: 0.05385\n",
      "Epoch [280001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00240, mean Relative L2 Loss: 0.05386\n",
      "Epoch [285001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00238, mean Relative L2 Loss: 0.05343\n",
      "Epoch [290001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00239, mean Relative L2 Loss: 0.05349\n",
      "Epoch [295001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00238, mean Relative L2 Loss: 0.05335\n",
      "Epoch [300001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00239, mean Relative L2 Loss: 0.05352\n",
      "Epoch [305001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00239, mean Relative L2 Loss: 0.05353\n",
      "Epoch [310001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00237, mean Relative L2 Loss: 0.05310\n",
      "Epoch [315001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00238, mean Relative L2 Loss: 0.05310\n",
      "Epoch [320001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00237, mean Relative L2 Loss: 0.05306\n",
      "Epoch [325001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00239, mean Relative L2 Loss: 0.05325\n",
      "Epoch [330001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00238, mean Relative L2 Loss: 0.05310\n",
      "Epoch [335001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00238, mean Relative L2 Loss: 0.05314\n",
      "Epoch [340001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00239, mean Relative L2 Loss: 0.05310\n",
      "Epoch [345001/500000], Loss: 0.0013\n",
      "Validation Loss: 0.00241, mean Relative L2 Loss: 0.05355\n",
      "Epoch [350001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00239, mean Relative L2 Loss: 0.05293\n",
      "Epoch [355001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00239, mean Relative L2 Loss: 0.05282\n",
      "Epoch [360001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00240, mean Relative L2 Loss: 0.05293\n",
      "Epoch [365001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00240, mean Relative L2 Loss: 0.05308\n",
      "Epoch [370001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00240, mean Relative L2 Loss: 0.05291\n",
      "Epoch [375001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00241, mean Relative L2 Loss: 0.05302\n",
      "Epoch [380001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00241, mean Relative L2 Loss: 0.05292\n",
      "Epoch [385001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00241, mean Relative L2 Loss: 0.05322\n",
      "Epoch [390001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00241, mean Relative L2 Loss: 0.05297\n",
      "Epoch [395001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00241, mean Relative L2 Loss: 0.05292\n",
      "Epoch [400001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00241, mean Relative L2 Loss: 0.05286\n",
      "Epoch [405001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00241, mean Relative L2 Loss: 0.05280\n",
      "Epoch [410001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00242, mean Relative L2 Loss: 0.05285\n",
      "Epoch [415001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00241, mean Relative L2 Loss: 0.05283\n",
      "Epoch [420001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00242, mean Relative L2 Loss: 0.05292\n",
      "Epoch [425001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00242, mean Relative L2 Loss: 0.05288\n",
      "Epoch [430001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00242, mean Relative L2 Loss: 0.05289\n",
      "Epoch [435001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00242, mean Relative L2 Loss: 0.05279\n",
      "Epoch [440001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00242, mean Relative L2 Loss: 0.05279\n",
      "Epoch [445001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00243, mean Relative L2 Loss: 0.05284\n",
      "Epoch [450001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00243, mean Relative L2 Loss: 0.05285\n",
      "Epoch [455001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00242, mean Relative L2 Loss: 0.05276\n",
      "Epoch [460001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00243, mean Relative L2 Loss: 0.05285\n",
      "Epoch [465001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00243, mean Relative L2 Loss: 0.05279\n",
      "Epoch [470001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00243, mean Relative L2 Loss: 0.05280\n",
      "Epoch [475001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00244, mean Relative L2 Loss: 0.05288\n",
      "Epoch [480001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00244, mean Relative L2 Loss: 0.05276\n",
      "Epoch [485001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00244, mean Relative L2 Loss: 0.05276\n",
      "Epoch [490001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00244, mean Relative L2 Loss: 0.05289\n",
      "Epoch [495001/500000], Loss: 0.0012\n",
      "Validation Loss: 0.00244, mean Relative L2 Loss: 0.05278\n",
      "Example 3 finished training, final error is: \n",
      "Validation Loss: 0.00245, mean Relative L2 Loss: 0.05283\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "'''\n",
    "    prepare data for deeponet\n",
    "'''\n",
    "np.random.seed(42) # fixed seed\n",
    "train_data, test_data = get_data(1000,200)\n",
    "train_data= [torch.from_numpy(d).float().to(device) for d in train_data]\n",
    "test_data = [torch.from_numpy(d).float().to(device) for d in test_data]\n",
    "(x_train, a_train, y_train, u_train) = train_data\n",
    "(x_test, a_test, y_test, u_test)     = test_data\n",
    "print(\"train shape:\", x_train.shape, a_train.shape, y_train.shape, u_train.shape)\n",
    "print(\"test shape:\", x_test.shape, a_test.shape, y_test.shape, u_test.shape)\n",
    "    \n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "for example_num in range(4):\n",
    "\n",
    "    print(f\"Using examples {example_num}\")\n",
    "    if example_num == 0:\n",
    "        model = DeepONet().to(device)\n",
    "    elif example_num == 1:\n",
    "        model = BelNet(num_learned_basis = 50, num_fixed_basis = 0)\n",
    "    elif example_num == 2:\n",
    "        low = 1\n",
    "        high = 30\n",
    "        num = high - low +1\n",
    "        def prior(w):\n",
    "            with torch.no_grad():\n",
    "                print(w.shape)\n",
    "                w.copy_(torch.linspace(low*2*torch.pi, high*2*torch.pi, num).view(num, 1))\n",
    "        basis = StochasticFeatures(kernel=\"trig symm\", x_dim=1, num_features=num, prior = prior)\n",
    "        model = BelNet(num_learned_basis = 50, num_fixed_basis = num*2, basis = basis)\n",
    "    elif example_num == 3:\n",
    "        low = 1\n",
    "        high = 30\n",
    "        num = high - low +1\n",
    "        def prior(w):\n",
    "            with torch.no_grad():\n",
    "                print(w.shape)\n",
    "                w.copy_(torch.linspace(low*2*torch.pi, high*2*torch.pi, num).view(num, 1))\n",
    "        basis = StochasticFeatures(kernel=\"trig symm\", x_dim=1, num_features=num, prior = prior)\n",
    "        model = BelNet(num_learned_basis = 0, num_fixed_basis = num*2, basis = basis)\n",
    "        \n",
    "    model = model.to(device)\n",
    "\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model has {count_parameters(model)} parameters\")\n",
    "    criterion = nn.MSELoss()  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    train_losses = train_model(model, train_data, test_data, criterion, optimizer, num_epochs=500000, device=device)\n",
    "    print(f\"Example {example_num} finished training, final error is: \")\n",
    "    validate_model(model, test_data, criterion, device=device)\n",
    "\n",
    "    # save model\n",
    "    torch.save(model.state_dict(), f'model_save_{example_num}.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
